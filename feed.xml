<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="https://vaibhav117.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://vaibhav117.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2022-12-15T21:14:27+00:00</updated><id>https://vaibhav117.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">How Torrents Work</title><link href="https://vaibhav117.github.io/blog/2018/How_Torrents_work/" rel="alternate" type="text/html" title="How Torrents Work"/><published>2018-08-20T15:31:19+00:00</published><updated>2018-08-20T15:31:19+00:00</updated><id>https://vaibhav117.github.io/blog/2018/How_Torrents_work</id><content type="html" xml:base="https://vaibhav117.github.io/blog/2018/How_Torrents_work/"><![CDATA[<p>Most of us must have used Torrents at some point of our lives. It’s an amazing utility that allows one to download large files with relative ease. Often, the technology behind Torrents, gets overshadowed by the constant inquisition about the morality of it’s usage.</p> <p>Only on delving deeper into the technology behind it, does one get to truly appreciate it’s brilliance. Without further ado, let’s jump right into it.</p> <p>Let’s start by understanding what a <em>p2p</em> application is.</p> <h2 id="a-brief-about-p2p-networking">A Brief about p2p networking</h2> <p>It’s an alternative to traditional Client Server architecture, wherein each member in the network is equal (more or less) and contributes in delivering the service the network is intended to provide. This implies that the role of a central server is nearly redundant. Such a system brings in some noteworthy advantages over the traditional approach -</p> <ul> <li>It improves availability by removing single point failures (though admittedly a well distributed server client system can do the same)</li> <li>There is no money spent on making data warehouses, large servers or establishing connections with monumental bandwidths. It distributes the storage, compute and bandwidth required across all the users on the network.</li> </ul> <p>It builds a self reliant ecosystem where everyone contributes and benefits. An application which uses such an approach to deliver the service is called a p2p application. Torrents happen to be amongst the mostly widely used p2p applications. Following this, let’s introduce ourselves to the BitTorrent (protocol): The primary Protocol used by torrents for the p2p transfer of files.</p> <h2 id="bittorrent-protocol">BitTorrent Protocol</h2> <h3 id="terminology">Terminology</h3> <ol> <li> <p><strong>Client</strong> : The program that enables p2p file sharing via the BitTorrent protocol.</p> </li> <li> <p><strong>Peer</strong> : A peer is one instance of a BitTorrent client running on a computer on the Internet to which other clients connect and transfer data.</p> </li> <li> <p><strong>Seeder</strong> : A peer that has the complete file and is now acting as a source for others. Having high numbers of seeders is huge positive as it’s a measure of availability.</p> </li> <li> <p><strong>Leecher</strong> : They’re peers who are in the process of downloading the file. They have parts of the file and keep gathering more parts over time. Once they finish their download, they become Seeders. They also act as sources of the parts of the files they’ve downloaded.</p> </li> </ol> <h3 id="format-of-the-file">Format of the File</h3> <p>The file is divided into pieces (also referred to as fragments), which are further split into sub-pieces. Clients can download a sub-piece from only one peer at a time. Therefore, to parallelise the download process, multiple sub-pieces are downloaded simultaneously from different peers.</p> <h3 id="tracker">Tracker</h3> <p>A tracker plays a very important role in the BitTorrent ecosystem. The tracker maintains information about all clients utilising each torrent and the meta-data about the torrent. Specifically, the tracker identifies the network location of each client either uploading or downloading the files associated with a torrent. It also tracks which fragment of that file each client possesses, to assist in efficient data sharing between clients. It’s essential to note that the tracker does not hold a copy of the file. It merely contains the meta data about the peers having or building copies of the file and information about the fragments that make up the complete file. So when a client approaches the Tracker to download the file, it simply reverts with the information about the peers involved in the file transfer and info about the file itself.</p> <h3 id="initial-upload">Initial Upload</h3> <p>When a new torrent is released, it’s seeded by a single peer, the peer releasing it. The peer registers the torrent with the Tracker (or with any of the Trackers in case of multi-tracker network). A torrent file is generated for the new release containing the address of the Tracker. Initially the original seeder is the only peer having a copy of the file. As peers start to download the file, the numbers of seeders and leechers increase, thus increasing the available copies of the file.</p> <h3 id="downloading-requests">Downloading Requests</h3> <p>When a peer starts downloading a particular torrent, it approaches a tracker associated with it. The Tracker relays meta-data about the torrent and the peers involved in the download. Using the algorithms mentioned later, the peer pings other peers and downloads the various pieces of the file. The actual sub-piece download is done using TCP protocol at network layer. To download the sub-pieces, the peer makes requests to other peers. These request are queued in a pipeline. It’s imperative to maintain the pipeline as BitTorrent uses TCP which implements a slow start mechanism. It is thus crucial to always transfer data or else the transfer rate will drop.</p> <h3 id="file-sharing-algorithm-used-by-peers">File Sharing Algorithm Used by Peers.</h3> <p>In a p2p network, the Peers themselves decide whom to download the pieces from. They follow the BitTorrent Protocol rules. These rules are essential to facilitate proper functioning of the network.</p> <p>Following are some of the rules that Clients follow while downloading-</p> <h4 id="piece-selection-algorithm">Piece Selection Algorithm</h4> <p>This is how the client decide which piece to download next. Piece selection is done to achieve a primary goal- Replication of different pieces on different peers as soon as possible. This will increase the download speed, and also make sure that all pieces of a file is somewhere in the network if the seeder leaves. While downloading the peers use the following rules to maximise they efficiency-</p> <ul> <li> <p><strong>Strict Policy</strong> : It prioritises of completion of a single piece over partial download of multiple pieces. Once a sub-piece is requested by the peer, other sub-pieces of the same piece are requested to be downloaded before others.</p> </li> <li> <p><strong>Rarest First</strong> : This aligns directly with the goal, wherein the next piece to be downloaded is the one which has fewest replicas. Not only does increase the availability but it also increases the download speeds for other peers looking for the piece.</p> </li> <li> <p><strong>Random First Piece</strong> : Since Bit-torrent protocol requires a peer to balance it’s upload and download, it’s wise to download the first piece as soon as possible. In coherence with this idea, the first piece is downloaded randomly instead to following the rarest first policy. Once the first piece is downloaded, the peer commences with the rarest first policy.</p> </li> <li> <p><strong>Endgame Mode</strong> : Towards the end of the download, when all the only sub-pieces remaining are the ones in the pipeline, the request is broadcasted to all peers. On the arrival of a sub-piece, a corresponding cancel request is sent. The network congestion caused by this is less than expected because of the it’s short duration.</p> </li> </ul> <h4 id="resource-allocation">Resource Allocation</h4> <p>The resource allocation of peers is managed by the peer themselves. Therefore the peers use protocols that award other peers who have been contributing and snubs those who haven’t been uploading themselves. This forces all peers to upload in order to maintain good download speeds. The aim for every node is to establish bidirectional channels with other peers, where both download and upload nearly the same amount to one another. This builds a stable p2p connection between the two nodes. To attain this goal, every peer uses the following strategies-</p> <ul> <li> <p>The peer cooperates on the first request made by any node. This is to initiate the communication between them.</p> </li> <li> <p>On the successive requests, the peers cooperation commensurates with cooperation received from the other peer.</p> </li> <li> <p><strong>Choking Algorithm</strong> : Peers always maintain a fixed number of unchoked peers. These are the peers that they are willing to upload to. These peers are selected on the upload rate offered by them. This provides an incentive to other peers to be good uploaders. If the unchoked peers are changed too often, the download speeds fall because of the slow start mechanism of TCP transfer. Therefore the list of unchoked peers is updated after a duration of 20 seconds.</p> </li> <li> <p><strong>Optimistic Unchoking</strong> : Peers select a random peer that they unchoke irrespective of the upload speed it offers. This peer is used as a wildcard entry to replace the peers selected by the choking algorithm. This allows the peer to discover new nodes which might offer better upload speeds. This peer is changed every 30 seconds. If in the duration, this peers is able to offer better upload speed than any of the other unchoked peers, they are swapped.</p> </li> <li> <p><strong>Anti-Snubbing</strong> : When a peer stops receiving data from a peer for about 60 seconds, it assumes that it has snubbed by that particular peer. To replace it, the node increases the number of Optimistically Unchoked peers. This allows the peer to recover faster in a scenario where it is snubbed by a large at the same time.</p> </li> <li> <p><strong>Upload Only</strong> : After a peer finishes a download, it uploads to peers having the highest download rate. This allows quick replication of data in the network.</p> </li> </ul> <p>These policies ensure that the pieces are replicated, and that every peer has the largest probability of retrieving the complete file, as quickly as possible. Inspired by “tit-for-tat”, the choking algorithm tries to prohibit “free riders” from destroying the dynamics of the peer-to-peer network. If a peer blocks other peers from uploading, he will soon be choked by them and thus affecting his download rate. The choking algorithm correlates the download rate to the upload rate. Uploading is encouraged and the price in return is a better chance for faster download</p> <p>The Bit-torrent protocol comes into play once the Client makes contact the Tracker. I’m sure you’re wondering how exactly does it manage to reach the tracker?</p> <h2 id="getting-to-the-tracker">Getting to the Tracker</h2> <p>Originally there was a single tracker for each torrent. This would be a special node entrusted to track the fragments of the torrent and the peers involved in the download. The location to this Tracker would be in the Torrent file. The torrent file would be listed on multiple web portals. Peers use these torrent file to get to the Tracker which in turns provides them the details to commence downloading the Torrent fragments. It’s evident what the drawbacks of such a system are. The single Tracker represents a single point failure and makes the system amenable to Denial Of Service Attacks. To fix this Multi-Tracker Torrents were introduced.</p> <h3 id="multi-tracker-torrents">Multi-Tracker Torrents</h3> <p>To tackle the aforementioned drawbacks of a single tracker, Multi-Tracker Torrents were devised. In this approach, every node in the network is equivalent. Trackers weren’t special nodes anymore. <a href="https://github.com/hydra-hoard/hydra/wiki/Distributed-Hash-Table-(DHT)-Algorithm">Distributed Hash Tables (DHTs)</a> were used to find and reach the Tracker to any Torrent. The torrent file now only contained the Hash of the Torrent, which would allow Peers to reach the Tracker using DHTs. Consistency amongst the Trackers is a different story in itself.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Most of us must have used Torrents at some point of our lives. It’s an amazing utility that allows one to download large files with relative ease. Often, the technology behind Torrents, gets overshadowed by the constant inquisition about the morality of it’s usage.]]></summary></entry><entry><title type="html">Advanced Go Concurrency Patterns</title><link href="https://vaibhav117.github.io/blog/2018/Advanced_Go_Concurrency_Patterns/" rel="alternate" type="text/html" title="Advanced Go Concurrency Patterns"/><published>2018-07-11T15:31:19+00:00</published><updated>2018-07-11T15:31:19+00:00</updated><id>https://vaibhav117.github.io/blog/2018/Advanced_Go_Concurrency_Patterns</id><content type="html" xml:base="https://vaibhav117.github.io/blog/2018/Advanced_Go_Concurrency_Patterns/"><![CDATA[<p>Concurrency in Go is implemented using Goroutines. Goroutines are functions or methods that run concurrently with other functions or methods. They can be thought of as light weight threads. The cost of creating a Goroutine is tiny when compared to a thread. Hence it’s common for Go applications to have thousands of Goroutines running concurrently.</p> <p>In-order to communicate between these Goroutines, Go implements channels. Channels send and receive data until the other side is ready. This allows Goroutines to synchronize without explicit locks or condition variables.</p> <h2 id="synchronized-channels">Synchronized Channels</h2> <p>Channels that don’t have a buffer size are called Synchronized Channels. The write and read functions halt till they are resolved. For instance- when we apply a read from a channel :</p> <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="o">&lt;-</span><span class="n">channel</span>
</code></pre></div></div> <p>The execution would not proceed beyond that line of code till the channel has a value to execute the read function. Similarly, in case of-</p> <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">channel</span> <span class="o">&lt;-</span> <span class="m">4</span>
</code></pre></div></div> <p>The execution halts till a reader removes the input. This allows us to synchronize Goroutines which otherwise work independently.</p> <h2 id="challenges-faced-in-making-goroutines">Challenges Faced in making Goroutines</h2> <p>The following problems occur commonly if Goroutines are used too cavalierly-</p> <h4 id="go-routines-dead-lock">Go Routines Dead Lock</h4> <p>It is a state when none of the Go routines are able to proceed. i.e - they are waiting for the other ones to provide a means of completion.</p> <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">func</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
     <span class="n">c</span> <span class="o">:=</span> <span class="nb">make</span><span class="p">(</span><span class="k">chan</span> <span class="kt">int</span><span class="p">)</span>
     <span class="n">c</span> <span class="o">&lt;-</span> <span class="m">42</span>    <span class="c">// write to a channel</span>
     <span class="n">val</span> <span class="o">:=</span> <span class="o">&lt;-</span><span class="n">c</span> <span class="c">// read from a channel</span>
     <span class="nb">println</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div> <p>In the above code a deadlock is formed because the code execution stops at <strong>c &lt;- 42</strong> and the statement <strong>val := &lt;-c</strong> is never evaluated.</p> <h4 id="race-conditions-in-go">Race conditions in GO</h4> <p>A race condition is when two or more routines have access to the same resource, such as a variable or data structure and attempt to read and write to that resource without any regard to the other routines. This type of code can create the craziest and most random bugs you have ever seen. It usually takes a tremendous amount of logging and luck to find these types of bugs Race conditions arise if we fire two Go Routines without proper initiation.</p> <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="p">(</span>
    <span class="s">"fmt"</span>
    <span class="s">"sync"</span>
<span class="p">)</span>

<span class="k">var</span> <span class="n">Counter</span> <span class="kt">int</span> <span class="o">=</span> <span class="m">0</span>

<span class="k">func</span> <span class="n">Routine</span><span class="p">(</span><span class="n">id</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="n">count</span> <span class="o">:=</span> <span class="m">0</span><span class="p">;</span> <span class="n">count</span> <span class="o">&lt;</span> <span class="m">2</span><span class="p">;</span> <span class="n">count</span><span class="o">++</span> <span class="p">{</span>
        <span class="n">value</span> <span class="o">:=</span> <span class="n">Counter</span>
        <span class="n">value</span><span class="o">++</span>
        <span class="n">Counter</span> <span class="o">=</span> <span class="n">value</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">func</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">for</span> <span class="n">routine</span> <span class="o">:=</span> <span class="m">1</span><span class="p">;</span> <span class="n">routine</span> <span class="o">&lt;=</span> <span class="m">2</span><span class="p">;</span> <span class="n">routine</span><span class="o">++</span> <span class="p">{</span>
        <span class="k">go</span> <span class="n">Routine</span><span class="p">(</span><span class="n">routine</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>In the above code, both Goroutines are racing to get the value <em>Counter</em> , add one to the value and write it back to <em>Counter</em>. In such a scenario, one of the Goroutines might alter the value of <em>Counter</em> after the other reads but before writes to it. So when the second Routine writes to <em>Counter</em>, it does so with the outdated value.</p> <p>Fortunately, Go provision to detect Race conditions. It can be detected using the following code-</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>go run <span class="nt">-race</span> file.go
</code></pre></div></div> <h4 id="sleep-in-go-routines">Sleep in Go routines</h4> <p>Go routines become unresponsive when in sleep mode. Therefore, if a condition occurs where we have to programmatically close the go routines without closing the program, the Go routines are lost and hog the cpu till there sleep ends. This is could be harmful in cases having long sleep durations. These Go routines would not be cleared for a long while.</p> <p>Let’s look at how to write programs that handle communication, periodic events, and cancellation. These can be mitigated using proper usage of Select construct.</p> <h2 id="select-construct">Select Construct</h2> <p>The core is Go’s select statement: like a switch, but the decision is made based on the ability to communicate.</p> <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">select</span> <span class="p">{</span>
<span class="k">case</span> <span class="n">xc</span> <span class="o">&lt;-</span> <span class="n">x</span><span class="o">:</span>
    <span class="c">// sent x on xc</span>
<span class="k">case</span> <span class="n">y</span> <span class="o">:=</span> <span class="o">&lt;-</span><span class="n">yc</span><span class="o">:</span>
    <span class="c">// received y from yc</span>
<span class="p">}</span>
</code></pre></div></div> <p>Select statement holds execution till one of it’s conditions is satisfied. This way all conditions can be checked simultaneously without being blocked at a statement. a default condition can also be added, if it is required to be executed if none of the conditions are satisfied. In that scenario, the select construct won’t wait if none of the conditions are satisfied.</p> <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">select</span> <span class="p">{</span>
<span class="k">case</span> <span class="n">xc</span> <span class="o">&lt;-</span> <span class="n">x</span><span class="o">:</span>
    <span class="c">// sent x on xc</span>
<span class="k">case</span> <span class="n">y</span> <span class="o">:=</span> <span class="o">&lt;-</span><span class="n">yc</span><span class="o">:</span>
    <span class="c">// received y from yc</span>
<span class="k">default</span><span class="o">:</span>
  <span class="n">fmt</span><span class="o">.</span><span class="n">Println</span><span class="p">(</span><span class="s">"No condition satisfied"</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div> <p>When more than one condition is satisfied, the case selected is at random between the successful ones.</p> <p>By using the Select Construct we can avoid dead locks as we provide an alternative to the program, if the read or write on the channel cannot proceed.</p> <p>Race conditions can also be resolved by proper implementation of channels select construct, without having to use Locks for Synchronization.</p> <h2 id="timeout-in-goroutine">Timeout in Goroutine</h2> <p>As noted above, using <strong><em>sleep</em></strong> in Go could possibly lead to rogue Goroutines. To avoid this we refrain from using sleep() at all. This is facilitated by the usage of <strong><em>Timeouts__**. **_Timeouts__** coupled with switch construct, provide an alternative to **_sleep</em></strong> in the following manner-</p> <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">select</span> <span class="p">{</span>
    <span class="k">case</span> <span class="o">&lt;-</span><span class="n">time</span><span class="o">.</span><span class="n">After</span><span class="p">(</span><span class="m">1</span> <span class="o">*</span> <span class="n">time</span><span class="o">.</span><span class="n">Second</span><span class="p">)</span><span class="o">:</span>
        <span class="n">fmt</span><span class="o">.</span><span class="n">Println</span><span class="p">(</span><span class="s">"timeout 1"</span><span class="p">)</span>
    <span class="p">}</span>
</code></pre></div></div> <p>So instead of using <strong><em>sleep</em></strong>, before we run <em>case res := &lt;-c1</em>, we use Timeout along with Switch Construct.</p> <p>This allows the Goroutine to be responsive even after adding a delay in it’s execution.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Concurrency in Go is implemented using Goroutines. Goroutines are functions or methods that run concurrently with other functions or methods. They can be thought of as light weight threads. The cost of creating a Goroutine is tiny when compared to a thread. Hence it’s common for Go applications to have thousands of Goroutines running concurrently.]]></summary></entry></feed>